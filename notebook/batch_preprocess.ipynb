{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Batch Preprocessing for 7-Day Urban Heat Island Dataset\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.warp import transform_bounds\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Parameters\n",
    "# ------------------------------\n",
    "DAYS = [187,196,205,215,212,223,240]\n",
    "PATCH_SIZE = 16\n",
    "STRIDE = 8\n",
    "NAN_THRESHOLD = 0.3\n",
    "TEMP_THRESHOLD = 303.0\n",
    "HOT_RATIO = 0.5\n",
    "OUTPUT_DIR = '../data/processed'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Geographic bounding box for DMV region (lat/lon)\n",
    "dmv_bounds_latlon = {\n",
    "    'left':  -77.8,\n",
    "    'right': -76.0,\n",
    "    'bottom': 38.2,\n",
    "    'top':    39.8\n",
    "}\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Define extraction function\n",
    "# ------------------------------\n",
    "def extract_patches_from_tif(day):\n",
    "    tif_path = f'../data/raw/gf_Day2020_{day}.tif'\n",
    "    print(f'\\n Processing Day {day}...')\n",
    "\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        # Convert lat/lon bounds to raster CRS\n",
    "        dmv_bounds_proj = transform_bounds('EPSG:4326', src.crs,\n",
    "                                           dmv_bounds_latlon['left'],\n",
    "                                           dmv_bounds_latlon['bottom'],\n",
    "                                           dmv_bounds_latlon['right'],\n",
    "                                           dmv_bounds_latlon['top'])\n",
    "        # Crop region\n",
    "        window = from_bounds(*dmv_bounds_proj, transform=src.transform)\n",
    "        patch = src.read(1, window=window).astype(np.float32)\n",
    "\n",
    "    patch[patch <= 0] = np.nan  # Replace invalid values\n",
    "\n",
    "    # Sliding window extraction\n",
    "    H, W = patch.shape\n",
    "    patches, labels = [], []\n",
    "\n",
    "    for i in range(0, H - PATCH_SIZE + 1, STRIDE):\n",
    "        for j in range(0, W - PATCH_SIZE + 1, STRIDE):\n",
    "            sub = patch[i:i+PATCH_SIZE, j:j+PATCH_SIZE]\n",
    "            if np.isnan(sub).mean() <= NAN_THRESHOLD:\n",
    "                valid = sub[~np.isnan(sub)]\n",
    "                hot_ratio = (valid > TEMP_THRESHOLD).mean() if len(valid) else 0.0\n",
    "                label = 1 if hot_ratio > HOT_RATIO else 0\n",
    "                patches.append(sub)\n",
    "                labels.append(label)\n",
    "\n",
    "    patches = np.array(patches, dtype=np.float32)\n",
    "    labels = np.array(labels, dtype=np.int64)\n",
    "\n",
    "    # Save per-day files\n",
    "    np.save(f\"{OUTPUT_DIR}/patches_day{day}_sw.npy\", patches)\n",
    "    np.save(f\"{OUTPUT_DIR}/labels_day{day}_sw.npy\", labels)\n",
    "\n",
    "    print(f\"Day {day}: {len(patches)} patches | UHI: {(labels==1).sum()} | Non-UHI: {(labels==0).sum()}\")\n",
    "    return len(patches), (labels==1).sum(), (labels==0).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing Day 187...\n",
      "Day 187: 767 patches | UHI: 304 | Non-UHI: 463\n",
      "\n",
      " Processing Day 196...\n",
      "Day 196: 767 patches | UHI: 275 | Non-UHI: 492\n",
      "\n",
      " Processing Day 205...\n",
      "Day 205: 767 patches | UHI: 404 | Non-UHI: 363\n",
      "\n",
      " Processing Day 215...\n",
      "Day 215: 767 patches | UHI: 343 | Non-UHI: 424\n",
      "\n",
      " Processing Day 212...\n",
      "Day 212: 767 patches | UHI: 312 | Non-UHI: 455\n",
      "\n",
      " Processing Day 223...\n",
      "Day 223: 767 patches | UHI: 360 | Non-UHI: 407\n",
      "\n",
      " Processing Day 240...\n",
      "Day 240: 767 patches | UHI: 369 | Non-UHI: 398\n",
      "\n",
      " Summary of all days:\n",
      "Day | Total | UHI | Non-UHI\n",
      "187 | 767 | 304 | 463\n",
      "196 | 767 | 275 | 492\n",
      "205 | 767 | 404 | 363\n",
      "215 | 767 | 343 | 424\n",
      "212 | 767 | 312 | 455\n",
      "223 | 767 | 360 | 407\n",
      "240 | 767 | 369 | 398\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 3. Process all days\n",
    "# ------------------------------\n",
    "summary = []\n",
    "\n",
    "for d in DAYS:\n",
    "    total, uhi, non_uhi = extract_patches_from_tif(d)\n",
    "    summary.append((d, total, uhi, non_uhi))\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n Summary of all days:\")\n",
    "print(\"Day | Total | UHI | Non-UHI\")\n",
    "for s in summary:\n",
    "    print(f\"{s[0]} | {s[1]} | {s[2]} | {s[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (4602, 16, 16) (4602,)\n",
      "Validation set: (767, 16, 16) (767,)\n",
      "Saved: patches_train.npy, labels_train.npy\n",
      "Saved: patches_val.npy, labels_val.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "processed_dir = \"../data/processed\"\n",
    "\n",
    "# --------------------------\n",
    "# 1. Define training / val days\n",
    "# --------------------------\n",
    "train_days = [187, 196, 205, 212, 223, 240]\n",
    "val_day = [215]\n",
    "\n",
    "# --------------------------\n",
    "# 2. Load & merge training days\n",
    "# --------------------------\n",
    "X_train = np.concatenate(\n",
    "    [np.load(f\"{processed_dir}/patches_day{d}_sw.npy\") for d in train_days],\n",
    "    axis=0\n",
    ")\n",
    "y_train = np.concatenate(\n",
    "    [np.load(f\"{processed_dir}/labels_day{d}_sw.npy\") for d in train_days],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "\n",
    "# --------------------------\n",
    "# 3. Load validation day\n",
    "# --------------------------\n",
    "X_val = np.load(f\"{processed_dir}/patches_day215_sw.npy\")\n",
    "y_val = np.load(f\"{processed_dir}/labels_day215_sw.npy\")\n",
    "\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "\n",
    "# --------------------------\n",
    "# 4. Save final merged dataset\n",
    "# --------------------------\n",
    "np.save(f\"{processed_dir}/patches_train.npy\", X_train)\n",
    "np.save(f\"{processed_dir}/labels_train.npy\", y_train)\n",
    "\n",
    "np.save(f\"{processed_dir}/patches_val.npy\", X_val)\n",
    "np.save(f\"{processed_dir}/labels_val.npy\", y_val)\n",
    "\n",
    "print(\"Saved: patches_train.npy, labels_train.npy\")\n",
    "print(\"Saved: patches_val.npy, labels_val.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
